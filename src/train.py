import argparse
import yaml
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
import sys
from pathlib import Path
from datetime import datetime
import csv
import json

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¼•å…¥å°ˆæ¡ˆæ¨¡çµ„
from src.models.cnn_lstm import CNNLSTM
from src.data.dataset import BadmintonDataset
from src.utils.metrics import calculate_metrics

def create_experiment_dir(config, experiment_name=None):
    """
    å‰µå»ºå¯¦é©—ç›®éŒ„ï¼Œå¸¶æ™‚é–“æˆ³
    
    Returns:
        Path: å¯¦é©—ç›®éŒ„è·¯å¾‘
        str: å¯¦é©— ID
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    if experiment_name is None:
        # å¾é…ç½®æ¨æ–·å¯¦é©—åç¨±
        dataset = Path(config['data']['processed_path']).name
        num_classes = config['data'].get('num_classes', 'unknown')
        experiment_name = f"{dataset}_{num_classes}class"
    
    experiment_id = f"{experiment_name}_{timestamp}"
    experiment_dir = Path("weights/experiments") / experiment_id
    experiment_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜é…ç½®åˆ°å¯¦é©—ç›®éŒ„
    with open(experiment_dir / "config.yaml", 'w') as f:
        yaml.dump(config, f)
    
    return experiment_dir, experiment_id

def log_training_result(experiment_id, config, metrics_dict, model_path):
    """
    è¨˜éŒ„è¨“ç·´çµæœåˆ° CSV
    
    Args:
        experiment_id: å¯¦é©— ID
        config: è¨“ç·´é…ç½®
        metrics_dict: åŒ…å«è¨“ç·´æŒ‡æ¨™çš„å­—å…¸
        model_path: æ¨¡å‹å„²å­˜è·¯å¾‘
    """
    csv_path = Path("results/training_history.csv")
    csv_path.parent.mkdir(parents=True, exist_ok=True)
    
    # æº–å‚™è¨˜éŒ„è³‡æ–™
    row = {
        'experiment_id': experiment_id,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'config_file': config.get('_config_file', 'unknown'),
        'dataset': Path(config['data']['processed_path']).name,
        'num_classes': config['data'].get('num_classes', 0),
        'epochs': config['training']['epochs'],
        'batch_size': config['training']['batch_size'],
        'learning_rate': config['training']['learning_rate'],
        'use_pretrained': config['model'].get('use_pretrained', True),
        'use_optical_flow': config['model'].get('use_optical_flow', False),
        'best_train_acc': f"{metrics_dict.get('train_acc', 0):.4f}",
        'best_train_f1': f"{metrics_dict.get('train_f1', 0):.4f}",
        'best_val_acc': f"{metrics_dict.get('val_acc', 0):.4f}",
        'best_val_f1': f"{metrics_dict.get('val_f1', 0):.4f}",
        'best_test_acc': f"{metrics_dict.get('test_acc', 0):.4f}",
        'best_test_f1': f"{metrics_dict.get('test_f1', 0):.4f}",
        'model_path': str(model_path),
        'notes': config.get('notes', '')
    }
    
    # å¯«å…¥ CSV
    file_exists = csv_path.exists()
    with open(csv_path, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=row.keys())
        if not file_exists or csv_path.stat().st_size == 0:
            writer.writeheader()
        writer.writerow(row)
    
    print(f"âœ“ è¨“ç·´è¨˜éŒ„å·²ä¿å­˜åˆ°: {csv_path}")

def train(config, experiment_name=None):
    """
    è¨“ç·´ä¸»å‡½å¼ã€‚
    
    Args:
        config (dict): è¨­å®šåƒæ•¸å­—å…¸ã€‚
    """
    # 0. å‰µå»ºå¯¦é©—ç›®éŒ„
    experiment_dir, experiment_id = create_experiment_dir(config, experiment_name)
    print(f"="*60)
    print(f"å¯¦é©— ID: {experiment_id}")
    print(f"å¯¦é©—ç›®éŒ„: {experiment_dir}")
    print(f"="*60)
    
    # 1. è¨­å®šè£ç½® (Device Setup)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # 2. æº–å‚™è³‡æ–™ (Data Preparation)
    from src.data.dataset import get_dataloaders
    
    dataloaders_dict = get_dataloaders(
        data_root=config['data']['processed_path'],
        batch_size=config['training']['batch_size'],
        seq_length=config['model'].get('seq_length', 16),
        num_workers=config['training'].get('num_workers', 4)
    )
    
    train_loader = dataloaders_dict.get('train')
    val_loader = dataloaders_dict.get('val')
    num_classes = dataloaders_dict.get('num_classes', config['data'].get('num_classes', 4))
    
    if train_loader is None:
        raise ValueError(f"No training data found in {config['data']['processed_path']}/train")
    
    print(f"Train set: {len(train_loader.dataset)} samples")
    if val_loader:
        print(f"Val set: {len(val_loader.dataset)} samples")
    print(f"Number of classes: {num_classes}")
    print(f"Class mapping: {dataloaders_dict.get('class_to_idx', {})}")

    # 3. åˆå§‹åŒ–æ¨¡å‹ (Model Initialization)
    use_pretrained = config['model'].get('use_pretrained', True)
    weights_path = None
    
    # è™•ç† use_pretrained åƒæ•¸
    if isinstance(use_pretrained, str):
        if use_pretrained.lower() == 'imagenet':
            use_pretrained = True
        elif use_pretrained.endswith('.pth') or os.path.exists(use_pretrained):
            weights_path = use_pretrained
            use_pretrained = False  # ä½¿ç”¨æœ¬åœ°æ¬Šé‡ï¼Œä¸å¾ç¶²è·¯ä¸‹è¼‰
            print(f"Using local backbone weights: {weights_path}")
        else:
            # å…¶ä»–å­—ä¸²æƒ…æ³ï¼ˆå¦‚ 'true'ï¼‰ï¼Œå˜—è©¦è½‰ç‚ºå¸ƒæ—å€¼
            use_pretrained = use_pretrained.lower() == 'true'

    model = CNNLSTM(
        num_classes=num_classes,
        hidden_size=config['model']['hidden_size'],
        num_layers=config['model'].get('num_lstm_layers', 2),
        pretrained=use_pretrained,
        use_optical_flow=config['model'].get('use_optical_flow', False),
        weights_path=weights_path
    ).to(device)
    
    # å¦‚æœæœ‰æŒ‡å®šé è¨“ç·´æ¬Šé‡è·¯å¾‘ (ä¾‹å¦‚ Transfer Learning)ï¼Œå‰‡è¼‰å…¥
    if 'pretrained_weights' in config['training'] and config['training']['pretrained_weights']:
        print(f"Loading pretrained weights from {config['training']['pretrained_weights']}")
        # é€™è£¡éœ€è¦æ ¹æ“šå„²å­˜æ ¼å¼èª¿æ•´ï¼Œå¦‚æœæ˜¯æ•´å€‹æ¨¡å‹æˆ– state_dict
        checkpoint = torch.load(config['training']['pretrained_weights'], map_location=device)
        # è™•ç†å¯èƒ½çš„ key ä¸åŒ¹é…å•é¡Œ (ä¾‹å¦‚å¤šå¡è¨“ç·´çš„ 'module.' å‰ç¶´)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        else:
            model.load_state_dict(checkpoint, strict=False)
            
    # å‡çµ Backbone (å¦‚æœè¨­å®šæª”è¦æ±‚)
    if config['training'].get('freeze_backbone', False):
        print("Freezing backbone layers...")
        for param in model.backbone.parameters():
            param.requires_grad = False

    # 4. å®šç¾© Loss èˆ‡ Optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()), # åªæ›´æ–°éœ€è¦æ¢¯åº¦çš„åƒæ•¸
        lr=float(config['training']['learning_rate'])
    )
    
    # å­¸ç¿’ç‡æ’ç¨‹å™¨ (Optional)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)

    # 5. è¨“ç·´è¿´åœˆ (Training Loop)
    best_val_f1 = 0.0
    best_metrics = {'train_acc': 0, 'train_f1': 0, 'val_acc': 0, 'val_f1': 0}
    save_dir = experiment_dir  # ä½¿ç”¨å¯¦é©—ç›®éŒ„
    
    epochs = config['training']['epochs']
    
    for epoch in range(epochs):
        # --- Training Phase ---
        model.train()
        train_loss = 0.0
        all_preds = []
        all_labels = []
        
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]")
        for batch in train_pbar:
            frames, labels = batch
            frames = frames.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(frames)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            # æ”¶é›†é æ¸¬çµæœä»¥è¨ˆç®—æŒ‡æ¨™
            preds = torch.argmax(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            train_pbar.set_postfix({'loss': loss.item()})
            
        train_metrics = calculate_metrics(np.array(all_labels), np.array(all_preds))
        avg_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0
        
        print(f"Epoch {epoch+1} Train: Loss={avg_train_loss:.4f}, Acc={train_metrics['accuracy']:.4f}, F1={train_metrics['f1']:.4f}")
        
        # --- Validation Phase ---
        model.eval()
        val_loss = 0.0
        val_preds = []
        val_labels = []
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]")
            for batch in val_pbar:
                frames, labels = batch
                frames = frames.to(device)
                labels = labels.to(device)
                
                outputs = model(frames)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                
                preds = torch.argmax(outputs, dim=1)
                val_preds.extend(preds.cpu().numpy())
                val_labels.extend(labels.cpu().numpy())
        
        val_metrics = calculate_metrics(np.array(val_labels), np.array(val_preds))
        avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0
        
        print(f"Epoch {epoch+1} Val: Loss={avg_val_loss:.4f}, Acc={val_metrics['accuracy']:.4f}, F1={val_metrics['f1']:.4f}")
        
        # æ›´æ–° Scheduler
        scheduler.step(val_metrics['f1'])
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_loader and val_metrics['f1'] > best_val_f1:
            best_val_f1 = val_metrics['f1']
            best_metrics.update({
                'train_acc': train_metrics['accuracy'],
                'train_f1': train_metrics['f1'],
                'val_acc': val_metrics['accuracy'],
                'val_f1': val_metrics['f1']
            })
            save_path = save_dir / "best_model.pth"
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_f1': best_val_f1,
                'config': config
            }, save_path)
            print(f"New best model saved to {save_path} (F1: {best_val_f1:.4f})")
    
    # è¨“ç·´å®Œæˆ
    print("\n" + "="*60)
    print("è¨“ç·´å®Œæˆï¼")
    print(f"æœ€ä½³é©—è­‰ F1: {best_val_f1:.4f}")
    print("="*60)
    
    # åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    test_loader = dataloaders_dict.get('test')
    if test_loader is not None:
        print("\n" + "="*60)
        print("æ­£åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°æœ€ä½³æ¨¡å‹...")
        print("="*60)
        
        # è¼‰å…¥æœ€ä½³æ¨¡å‹
        best_model_path = save_dir / "best_model.pth"
        checkpoint = torch.load(best_model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        # åœ¨æ¸¬è©¦é›†ä¸Šæ¨è«–
        test_preds = []
        test_labels = []
        
        with torch.no_grad():
            test_pbar = tqdm(test_loader, desc="Testing")
            for batch in test_pbar:
                frames, labels = batch
                frames = frames.to(device)
                labels = labels.to(device)
                
                outputs = model(frames)
                preds = torch.argmax(outputs, dim=1)
                test_preds.extend(preds.cpu().numpy())
                test_labels.extend(labels.cpu().numpy())
        
        # è¨ˆç®—æ¸¬è©¦æŒ‡æ¨™
        test_metrics = calculate_metrics(np.array(test_labels), np.array(test_preds))
        
        print(f"\næ¸¬è©¦çµæœ: Acc={test_metrics['accuracy']:.4f}, F1={test_metrics['f1']:.4f}")
        
        # æ›´æ–° best_metrics
        best_metrics.update({
            'test_acc': test_metrics['accuracy'],
            'test_f1': test_metrics['f1']
        })
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ°æ¸¬è©¦é›†ï¼Œè·³éæ¸¬è©¦è©•ä¼°")
    
    # è¨˜éŒ„åˆ° CSV
    log_training_result(
        experiment_id=experiment_id,
        config=config,
        metrics_dict=best_metrics,
        model_path=save_dir / "best_model.pth"
    )
    
    return experiment_dir, best_metrics

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, required=True, help="Path to config file")
    parser.add_argument("--pretrained_weights", type=str, help="Path to pretrained weights (override config)")
    parser.add_argument("--experiment_name", type=str, help="Custom experiment name (optional)")
    args = parser.parse_args()
    
    with open(args.config, "r") as f:
        config = yaml.safe_load(f)
    
    # è¨˜éŒ„é…ç½®æ–‡ä»¶åç¨±
    config['_config_file'] = os.path.basename(args.config)
    
    # å…è¨±å¾å‘½ä»¤åˆ—è¦†è“‹é è¨“ç·´æ¬Šé‡è·¯å¾‘
    if args.pretrained_weights:
        if 'training' not in config:
            config['training'] = {}
        config['training']['pretrained_weights'] = args.pretrained_weights
    
    # åŸ·è¡Œè¨“ç·´
    experiment_dir, metrics = train(config, experiment_name=args.experiment_name)
    
    print(f"\nâœ… è¨“ç·´å®Œæˆï¼")
    print(f"ğŸ“ å¯¦é©—ç›®éŒ„: {experiment_dir}")
    print(f"ğŸ“Š è¨“ç·´è¨˜éŒ„: results/training_history.csv")

